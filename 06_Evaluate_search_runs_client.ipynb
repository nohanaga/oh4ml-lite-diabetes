{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3Step Pipeline Example (Train, Evaluate, Register)\r\n",
        "## mlflow.search_runs version"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile search_scripts/train.py\r\n",
        "# Copyright (c) Microsoft. All rights reserved.\r\n",
        "# Licensed under the MIT license.\r\n",
        "\r\n",
        "import argparse\r\n",
        "import mlflow\r\n",
        "import os\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "from sklearn.linear_model import Ridge\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument(\"--input_data\", type=str, help=\"input data\")\r\n",
        "    parser.add_argument(\"--model_output\", type=str, help=\"model output\", default=\"./outputs\")\r\n",
        "\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    return args\r\n",
        "\r\n",
        "args = parse_args()\r\n",
        "lines = [\r\n",
        "    f\"Training data path: {args.input_data}\",\r\n",
        "    f\"Model output path: {args.model_output}\"\r\n",
        "]\r\n",
        "for line in lines:\r\n",
        "    print(line)\r\n",
        "\r\n",
        "with mlflow.start_run():\r\n",
        "    mlflow.log_text('input_data', args.input_data)\r\n",
        "    \r\n",
        "    diabetes_data = np.loadtxt(args.input_data, delimiter=',',skiprows=1)\r\n",
        "    X=diabetes_data[:,0:-1]\r\n",
        "    y=diabetes_data[:,-1]\r\n",
        "    columns = ['age', 'gender', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\r\n",
        "    data = {\r\n",
        "        \"train\": {\"X\": X_train, \"y\": y_train},\r\n",
        "        \"test\": {\"X\": X_test, \"y\": y_test}}\r\n",
        "\r\n",
        "    mlflow.log_metric(\"Training samples\", len(data['train']['X']))\r\n",
        "    mlflow.log_metric(\"Test samples\", len(data['test']['X']))\r\n",
        "\r\n",
        "    # Log the algorithm parameter alpha to the run\r\n",
        "    mlflow.log_metric('alpha', 0.03)\r\n",
        "    # Create, fit, and test the scikit-learn Ridge regression model\r\n",
        "    regression_model = Ridge(alpha=0.03)\r\n",
        "    regression_model.fit(data['train']['X'], data['train']['y'])\r\n",
        "    preds = regression_model.predict(data['test']['X'])\r\n",
        "\r\n",
        "    # Log mean squared error\r\n",
        "    mse = mean_squared_error(data['test']['y'], preds)\r\n",
        "    print('Mean Squared Error is', mse)\r\n",
        "    mlflow.log_metric('mse', mse)\r\n",
        "\r\n",
        "    # Save the model to the outputs directory for capture\r\n",
        "    mlflow.sklearn.save_model(regression_model, args.model_output)\r\n",
        "    mlflow.log_artifact(args.model_output)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile search_scripts/evaluate.py\r\n",
        "\r\n",
        "import argparse\r\n",
        "import json\r\n",
        "import mlflow\r\n",
        "from mlflow.pyfunc import load_model\r\n",
        "from mlflow.tracking import MlflowClient\r\n",
        "import time\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument('--experiment_name', type=str, help='Experiment Name')\r\n",
        "    parser.add_argument('--model_name', type=str, help='Name under which model will be registered')\r\n",
        "    parser.add_argument('--model_path', type=str, help='Model directory')\r\n",
        "    parser.add_argument('--output_path', type=str, help=\"eval output\", default='./outputs')\r\n",
        "\r\n",
        "    args, _ = parser.parse_known_args()\r\n",
        "    print(f'Arguments: {args}')\r\n",
        "\r\n",
        "    return args\r\n",
        "\r\n",
        "def main():\r\n",
        "\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    model_name = args.model_name\r\n",
        "    model_path = args.model_path\r\n",
        "    output_path = args.output_path\r\n",
        "    deploy_flag = 0\r\n",
        "    \r\n",
        "    mlflow.set_tag(\"model_name\", model_name)\r\n",
        "    mlflow.set_tag(\"model_path\", model_path)\r\n",
        "\r\n",
        "    time.sleep(60)\r\n",
        "\r\n",
        "    #Experiment Name から最新の Run を取得する\r\n",
        "    experimentName = args.experiment_name\r\n",
        "    experiment = mlflow.get_experiment_by_name(experimentName)\r\n",
        "\r\n",
        "    client = MlflowClient() \r\n",
        "    all_run = client.search_runs(\r\n",
        "    experiment_ids = experiment.experiment_id,\r\n",
        "    filter_string = \"metrics.mse > 0\"\r\n",
        "    )\r\n",
        "    #すでに実行順(昇順)になっている？ -> df を逆順に\r\n",
        "    all_run.reverse()\r\n",
        "\r\n",
        "    #[debug] search_runs をフィルタなしで全件 stdout\r\n",
        "    all_run2 = client.search_runs(\r\n",
        "    experiment_ids = experiment.experiment_id,\r\n",
        "    filter_string = \"\"\r\n",
        "    )\r\n",
        "    all_run2.reverse()\r\n",
        "    \r\n",
        "    for ret in all_run2:\r\n",
        "        print(ret.info.run_id, ret.data.metrics.get('mse', \"N/A\"), ret.data.metrics.get('run_mse', \"N/A\"))\r\n",
        "\r\n",
        "    #前段の Run から精度(mse)を取得\r\n",
        "    run_mse = all_run[0].data.metrics.get('mse', 0)\r\n",
        "    run_id = all_run[0].info.run_id\r\n",
        "    print(\"run_mse: \" + str(run_mse))\r\n",
        "    print(\"run_id: \" + str(run_id))\r\n",
        "    try:\r\n",
        "        #最新の登録済みモデルを取得\r\n",
        "        model_info = client.get_registered_model(model_name)\r\n",
        "        model_tags = model_info.latest_versions[0].tags\r\n",
        "        #Model の精度(mse)\r\n",
        "        model_mse = float(model_tags[\"mse\"])\r\n",
        "        mlflow.log_metric('model_mse', model_mse)\r\n",
        "        print(\"model_mse: \" + str(model_mse))\r\n",
        "        \r\n",
        "        #mse 比較\r\n",
        "        if run_mse < model_mse:\r\n",
        "            print(\"精度が上回りました\")\r\n",
        "            deploy_flag = 1\r\n",
        "\r\n",
        "        else:\r\n",
        "            print(\"精度が上回りませんでした\")\r\n",
        "            deploy_flag = 0\r\n",
        "    \r\n",
        "    except:\r\n",
        "        print(\"モデルがないよ→そのまま登録させる\")\r\n",
        "        deploy_flag = 1\r\n",
        "\r\n",
        "    mlflow.log_metric('run_mse', run_mse)\r\n",
        "    mlflow.set_tag(\"deploy_flag\", deploy_flag)\r\n",
        "\r\n",
        "    with open(output_path + \"/output_evaluate.txt\", \"w\") as f:\r\n",
        "        f.write(\"hello\")\r\n",
        "    mlflow.log_artifact(output_path)\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    main()\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile search_scripts/register.py\r\n",
        "\r\n",
        "import argparse\r\n",
        "import json\r\n",
        "import mlflow\r\n",
        "from mlflow.pyfunc import load_model\r\n",
        "from mlflow.tracking import MlflowClient\r\n",
        "import time\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument('--experiment_name', type=str, help='Experiment Name')\r\n",
        "    parser.add_argument('--model_name', type=str, help='Name under which model will be registered')\r\n",
        "    parser.add_argument('--model_path', type=str, help='Model directory')\r\n",
        "    parser.add_argument('--eval_path', type=str, help='eval directory')\r\n",
        "    \r\n",
        "    args, _ = parser.parse_known_args()\r\n",
        "    print(f'Arguments: {args}')\r\n",
        "\r\n",
        "    return args\r\n",
        "\r\n",
        "\r\n",
        "def main():\r\n",
        "\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    model_name = args.model_name\r\n",
        "    model_path = args.model_path\r\n",
        "    eval_path = args.eval_path\r\n",
        "\r\n",
        "    mlflow.set_tag(\"model_name\", model_name)\r\n",
        "    mlflow.set_tag(\"model_path\", model_path)\r\n",
        "\r\n",
        "    #Experiment Name から最新の Run を取得する\r\n",
        "    experimentName = args.experiment_name\r\n",
        "    experiment = mlflow.get_experiment_by_name(experimentName)\r\n",
        "\r\n",
        "    time.sleep(60)\r\n",
        "\r\n",
        "    client = MlflowClient() \r\n",
        "    all_run = client.search_runs(\r\n",
        "    experiment_ids = experiment.experiment_id,\r\n",
        "    filter_string = \"metrics.run_mse > 0\"\r\n",
        "    )\r\n",
        "    #すでに実行順(昇順)になっている？ -> df を逆順に\r\n",
        "    all_run.reverse()\r\n",
        "    \r\n",
        "    #前段の Run から精度(mse)を取得\r\n",
        "    run_mse = all_run[0].data.metrics.get('run_mse', 0)\r\n",
        "    deploy_flag = int(all_run[0].data.tags.get('deploy_flag', 0))\r\n",
        "    run_id = all_run[0].info.run_id\r\n",
        "    print(\"run_mse: \" + str(run_mse))\r\n",
        "    print(\"deploy_flag: \" + str(deploy_flag))\r\n",
        "    print(\"run_id: \" + str(run_id))\r\n",
        "\r\n",
        "    mlflow.log_metric(\"run_mse\", run_mse)\r\n",
        "    mlflow.set_tag(\"deploy_flag\", deploy_flag)\r\n",
        "\r\n",
        "    if deploy_flag==1:\r\n",
        "        #model_path から model をロード\r\n",
        "        model = load_model(model_path) \r\n",
        "        # Log the sklearn model and register as version 1\r\n",
        "        modelreg = mlflow.sklearn.log_model(\r\n",
        "            sk_model=model,\r\n",
        "            artifact_path=model_name,\r\n",
        "            registered_model_name=model_name\r\n",
        "        )\r\n",
        "        print(modelreg)\r\n",
        "\r\n",
        "        #log_model では モデルに tag が登録できないので、別途 set_model_version_tag 使ってる（エレガントではない）\r\n",
        "        model_info = client.get_registered_model(model_name)\r\n",
        "        model_version = model_info.latest_versions[0].version\r\n",
        "        client.set_model_version_tag(model_name, str(model_version), \"mse\", run_mse)\r\n",
        "        print(\"Model registered!\")\r\n",
        "    else:\r\n",
        "        print(\"Model will not be registered!\")\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    main()\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 06_pipeline_job_3step_client.yml\r\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\r\n",
        "type: pipeline\r\n",
        "experiment_name: 06_pipeline_oh4ml_3step_client\r\n",
        "description: 3Step Pipeline Example (Train, Evaluate, Register)\r\n",
        "\r\n",
        "# <inputs_and_outputs>\r\n",
        "inputs:\r\n",
        "  input: \r\n",
        "    type: uri_file\r\n",
        "    #path: azureml:diabetes_data_oh4ml@latest\r\n",
        "    path: azureml:diabetes_data_oh4ml_350records@latest\r\n",
        "  experiment_name: 06_pipeline_oh4ml_3step_client\r\n",
        "  model_name: diabetes_model_oh4ml_client2\r\n",
        "outputs: \r\n",
        "  trained_model:\r\n",
        "\r\n",
        "settings:\r\n",
        "  default_datastore: azureml:workspaceblobstore\r\n",
        "  default_compute: azureml:eightcorecluster\r\n",
        "  continue_on_step_failure: false\r\n",
        "\r\n",
        "jobs:\r\n",
        "  train_model:\r\n",
        "    name: train_model\r\n",
        "    display_name: train-model\r\n",
        "    code: ./search_scripts\r\n",
        "    command: >-\r\n",
        "      python train.py \r\n",
        "      --input_data ${{inputs.diabetes_data}} \r\n",
        "      --model_output ${{outputs.model_output}}\r\n",
        "    environment: azureml:diabetes-env-02@latest\r\n",
        "    inputs:\r\n",
        "      diabetes_data: ${{parent.inputs.input}}\r\n",
        "    outputs:\r\n",
        "      model_output: ${{parent.outputs.trained_model}}\r\n",
        "\r\n",
        "  evaluate_model:\r\n",
        "    name: evaluate_model\r\n",
        "    display_name: evaluate-model\r\n",
        "    code: ./search_scripts\r\n",
        "    command: >-\r\n",
        "      python evaluate.py \r\n",
        "      --experiment_name ${{inputs.experiment_name}} \r\n",
        "      --model_name ${{inputs.model_name}} \r\n",
        "      --model_path ${{inputs.model_path}} \r\n",
        "      --output_path ${{outputs.evaluate_output}}\r\n",
        "    environment: azureml:diabetes-env-02@latest\r\n",
        "    inputs:\r\n",
        "      model_name: ${{parent.inputs.model_name}}\r\n",
        "      model_path: ${{parent.jobs.train_model.outputs.model_output}}\r\n",
        "      experiment_name: ${{parent.inputs.experiment_name}}\r\n",
        "    outputs:\r\n",
        "      evaluate_output: \r\n",
        "\r\n",
        "  register_model:\r\n",
        "    name: register_model\r\n",
        "    display_name: register-model\r\n",
        "    code: ./search_scripts\r\n",
        "    command: >-\r\n",
        "      python register.py \r\n",
        "      --experiment_name ${{inputs.experiment_name}} \r\n",
        "      --model_name ${{inputs.model_name}} \r\n",
        "      --model_path ${{inputs.model_path}} \r\n",
        "      --eval_path ${{inputs.eval_path}}\r\n",
        "    environment: azureml:diabetes-env-02@latest\r\n",
        "    inputs:\r\n",
        "      model_name: ${{parent.inputs.model_name}}\r\n",
        "      model_path: ${{parent.jobs.train_model.outputs.model_output}}\r\n",
        "      eval_path: ${{parent.jobs.evaluate_model.outputs.evaluate_output}}\r\n",
        "      experiment_name: ${{parent.inputs.experiment_name}}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!az login"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!az ml job create -n 04_test_pipeline-client-06 -f 06_pipeline_job_3step_client.yml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}